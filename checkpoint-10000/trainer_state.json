{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.6025760173797607,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.2779,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.032623529434204,
      "learning_rate": 4.9e-05,
      "loss": 1.111,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 28.272132873535156,
      "learning_rate": 4.85e-05,
      "loss": 0.9876,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8656733632087708,
      "learning_rate": 4.8e-05,
      "loss": 0.4029,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5313023924827576,
      "learning_rate": 4.75e-05,
      "loss": 0.322,
      "step": 500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.47689589858055115,
      "learning_rate": 4.7e-05,
      "loss": 0.2912,
      "step": 600
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6402755975723267,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.2931,
      "step": 700
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6870656609535217,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.2848,
      "step": 800
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6436027884483337,
      "learning_rate": 4.55e-05,
      "loss": 0.2868,
      "step": 900
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.831026554107666,
      "learning_rate": 4.5e-05,
      "loss": 0.3255,
      "step": 1000
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0217654705047607,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.3001,
      "step": 1100
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5981292128562927,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.3048,
      "step": 1200
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5503545999526978,
      "learning_rate": 4.35e-05,
      "loss": 0.2716,
      "step": 1300
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.6226043701171875,
      "learning_rate": 4.3e-05,
      "loss": 0.2959,
      "step": 1400
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5427757501602173,
      "learning_rate": 4.25e-05,
      "loss": 0.2589,
      "step": 1500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8198174834251404,
      "learning_rate": 4.2e-05,
      "loss": 0.2666,
      "step": 1600
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.666631281375885,
      "learning_rate": 4.15e-05,
      "loss": 0.2695,
      "step": 1700
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.640798032283783,
      "learning_rate": 4.1e-05,
      "loss": 0.2616,
      "step": 1800
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1271400451660156,
      "learning_rate": 4.05e-05,
      "loss": 0.2802,
      "step": 1900
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5073760151863098,
      "learning_rate": 4e-05,
      "loss": 0.2504,
      "step": 2000
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1129748821258545,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.2617,
      "step": 2100
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6875722408294678,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.2623,
      "step": 2200
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6752622723579407,
      "learning_rate": 3.85e-05,
      "loss": 0.2514,
      "step": 2300
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5371710658073425,
      "learning_rate": 3.8e-05,
      "loss": 0.2331,
      "step": 2400
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5226818323135376,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.2583,
      "step": 2500
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6201391816139221,
      "learning_rate": 3.7e-05,
      "loss": 0.2344,
      "step": 2600
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6386197209358215,
      "learning_rate": 3.65e-05,
      "loss": 0.2603,
      "step": 2700
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8939934968948364,
      "learning_rate": 3.6e-05,
      "loss": 0.2313,
      "step": 2800
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6414103507995605,
      "learning_rate": 3.55e-05,
      "loss": 0.2308,
      "step": 2900
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7059141397476196,
      "learning_rate": 3.5e-05,
      "loss": 0.2476,
      "step": 3000
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7562957406044006,
      "learning_rate": 3.45e-05,
      "loss": 0.2619,
      "step": 3100
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7147547006607056,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.24,
      "step": 3200
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.755463182926178,
      "learning_rate": 3.35e-05,
      "loss": 0.2272,
      "step": 3300
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.7240387201309204,
      "learning_rate": 3.3e-05,
      "loss": 0.2392,
      "step": 3400
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6699674129486084,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.2443,
      "step": 3500
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.43865302205085754,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.2363,
      "step": 3600
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8187875747680664,
      "learning_rate": 3.15e-05,
      "loss": 0.2221,
      "step": 3700
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7188721299171448,
      "learning_rate": 3.1e-05,
      "loss": 0.235,
      "step": 3800
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7982860207557678,
      "learning_rate": 3.05e-05,
      "loss": 0.2303,
      "step": 3900
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4804871380329132,
      "learning_rate": 3e-05,
      "loss": 0.2308,
      "step": 4000
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0092077255249023,
      "learning_rate": 2.95e-05,
      "loss": 0.2168,
      "step": 4100
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4902797341346741,
      "learning_rate": 2.9e-05,
      "loss": 0.2208,
      "step": 4200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.47532135248184204,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.2193,
      "step": 4300
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7072140574455261,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.2315,
      "step": 4400
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3945061266422272,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.2286,
      "step": 4500
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6304012537002563,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.215,
      "step": 4600
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7051665186882019,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.2317,
      "step": 4700
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6498374342918396,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.2164,
      "step": 4800
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8148027062416077,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.2255,
      "step": 4900
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5204350352287292,
      "learning_rate": 2.5e-05,
      "loss": 0.2342,
      "step": 5000
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5905463099479675,
      "learning_rate": 2.45e-05,
      "loss": 0.2324,
      "step": 5100
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3848230242729187,
      "learning_rate": 2.4e-05,
      "loss": 0.2093,
      "step": 5200
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9306644797325134,
      "learning_rate": 2.35e-05,
      "loss": 0.2332,
      "step": 5300
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7197014093399048,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.2161,
      "step": 5400
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8833741545677185,
      "learning_rate": 2.25e-05,
      "loss": 0.217,
      "step": 5500
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3153916597366333,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.227,
      "step": 5600
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.47396475076675415,
      "learning_rate": 2.15e-05,
      "loss": 0.2175,
      "step": 5700
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.49299511313438416,
      "learning_rate": 2.1e-05,
      "loss": 0.2243,
      "step": 5800
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7113280296325684,
      "learning_rate": 2.05e-05,
      "loss": 0.219,
      "step": 5900
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9669905304908752,
      "learning_rate": 2e-05,
      "loss": 0.2078,
      "step": 6000
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4781315326690674,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.2071,
      "step": 6100
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5977222323417664,
      "learning_rate": 1.9e-05,
      "loss": 0.1981,
      "step": 6200
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5620465874671936,
      "learning_rate": 1.85e-05,
      "loss": 0.1983,
      "step": 6300
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8547495007514954,
      "learning_rate": 1.8e-05,
      "loss": 0.2196,
      "step": 6400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6736526489257812,
      "learning_rate": 1.75e-05,
      "loss": 0.2068,
      "step": 6500
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.39427340030670166,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.206,
      "step": 6600
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5862615704536438,
      "learning_rate": 1.65e-05,
      "loss": 0.1974,
      "step": 6700
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5717472434043884,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.2207,
      "step": 6800
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3643145561218262,
      "learning_rate": 1.55e-05,
      "loss": 0.2238,
      "step": 6900
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3345685005187988,
      "learning_rate": 1.5e-05,
      "loss": 0.2264,
      "step": 7000
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5528478026390076,
      "learning_rate": 1.45e-05,
      "loss": 0.2016,
      "step": 7100
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6250059604644775,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.2048,
      "step": 7200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7375203967094421,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.1978,
      "step": 7300
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6557047963142395,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.198,
      "step": 7400
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.479084849357605,
      "learning_rate": 1.25e-05,
      "loss": 0.204,
      "step": 7500
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5293979048728943,
      "learning_rate": 1.2e-05,
      "loss": 0.1888,
      "step": 7600
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.46471115946769714,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.208,
      "step": 7700
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7754600644111633,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.2032,
      "step": 7800
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5127392411231995,
      "learning_rate": 1.05e-05,
      "loss": 0.2088,
      "step": 7900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.754169225692749,
      "learning_rate": 1e-05,
      "loss": 0.2177,
      "step": 8000
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6015565395355225,
      "learning_rate": 9.5e-06,
      "loss": 0.2238,
      "step": 8100
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5721530914306641,
      "learning_rate": 9e-06,
      "loss": 0.2074,
      "step": 8200
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7756989002227783,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.2094,
      "step": 8300
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6019548773765564,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.2081,
      "step": 8400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5528650879859924,
      "learning_rate": 7.5e-06,
      "loss": 0.1931,
      "step": 8500
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4235023260116577,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.2075,
      "step": 8600
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.040990948677063,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.2008,
      "step": 8700
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5166507363319397,
      "learning_rate": 6e-06,
      "loss": 0.1926,
      "step": 8800
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5220810174942017,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.2036,
      "step": 8900
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5663968324661255,
      "learning_rate": 5e-06,
      "loss": 0.1987,
      "step": 9000
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5350345373153687,
      "learning_rate": 4.5e-06,
      "loss": 0.1874,
      "step": 9100
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6171955466270447,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2238,
      "step": 9200
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5522608757019043,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.2056,
      "step": 9300
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2939950227737427,
      "learning_rate": 3e-06,
      "loss": 0.2065,
      "step": 9400
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6797189116477966,
      "learning_rate": 2.5e-06,
      "loss": 0.2079,
      "step": 9500
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.730800211429596,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.1994,
      "step": 9600
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5740189552307129,
      "learning_rate": 1.5e-06,
      "loss": 0.1905,
      "step": 9700
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5938445329666138,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.2012,
      "step": 9800
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.4210258424282074,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.1939,
      "step": 9900
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5084568858146667,
      "learning_rate": 0.0,
      "loss": 0.2181,
      "step": 10000
    }
  ],
  "logging_steps": 100,
  "max_steps": 10000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.334259535872e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
